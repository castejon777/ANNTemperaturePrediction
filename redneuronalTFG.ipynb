{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "redneuronalTFG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castejon777/ANNTemperaturePrediction/blob/main/redneuronalTFG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyYnuncVtnxn"
      },
      "source": [
        "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#import os\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "#!pip install analytics-zoo\n",
        "\n",
        "!pip install pyspark\n",
        "\n",
        "#tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('App Name').getOrCreate()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from sklearn import metrics\n",
        "\n",
        "from datetime import datetime \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!pip3 install ann_visualizer\n",
        "from ann_visualizer.visualize import ann_viz;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NKrKc6dnKys"
      },
      "source": [
        "#Declaracion de las variables globales necesarias\n",
        "df = pd.DataFrame()\n",
        "train = pd.DataFrame()\n",
        "test = pd.DataFrame()\n",
        "x_label = pd.DataFrame()\n",
        "y_label = pd.DataFrame()\n",
        "x_test = pd.DataFrame()\n",
        "y_test = pd.DataFrame()\n",
        "xin_test = pd.DataFrame()\n",
        "yin_test  = pd.DataFrame()\n",
        "xout_test = pd.DataFrame()\n",
        "yout_test = pd.DataFrame()\n",
        "xret_test = pd.DataFrame()\n",
        "yret_test = pd.DataFrame()\n",
        "model = tf.keras.Sequential()\n",
        "predictions = pd.DataFrame()\n",
        "times = 0\n",
        "tempmax = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw-R4tLc4PFU"
      },
      "source": [
        "#Se leen las dos bases de datos y se almacenan en variables\n",
        "data_raw = spark.read.option(\"multiline\", \"true\").parquet('/content/drive/MyDrive/data/interxion/telemetry').toPandas()\n",
        "nodes = spark.read.option(\"multiline\", \"true\").json('/content/drive/MyDrive/data/interxion/location/location.json').toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL5Tqsi0i5ru"
      },
      "source": [
        "#Funcion necesaria para el preproceso previo de los datos\n",
        "def preparacionDataFrame():\n",
        "  global df\n",
        "  formato = \"%H:%M\"\n",
        "  #Se unen las dos bases de datos\n",
        "  df = data_raw.merge(nodes, left_on='macaddress', right_on='macaddress', how='left')\n",
        "  df['timeID'] = pd.to_datetime(df.timeID)\n",
        "\n",
        "  #Preparamos los datos de la hora para introducirlos en la red neuronal en función de los minutos del día\n",
        "  hhmmss = df['timeID']\n",
        "  horas = hhmmss.dt.hour\n",
        "  minutos = hhmmss.dt.minute\n",
        "  hhmmss_min = horas * 60 + minutos \n",
        "  minutos = hhmmss_min / (60*24)\n",
        "  df['time']=  minutos\n",
        "  df['temperature'] = df['temperature'] / 100\n",
        "  df['temperature10min'] = df['temperature'].loc[(df.time >= (0.08333333333333333+10/(24*60) ))].copy()\n",
        "  df[['temperature10min']] = df[['temperature10min']].fillna(value=df[['temperature10min']].mean())\n",
        "\n",
        "preparacionDataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUulOP4s_A1E"
      },
      "source": [
        "#Selecciona el porcentaje deseado de los datos totales del dataframe, de forma aleatoria\n",
        "#coef: introducir el porcentaje [0, 1] de las instancias que se desean\n",
        "#seed: parámetro numerico que se usa para recopilar siempre el mismo conjunto de instancias aleatorias (ej: si se pone 1 siempre, se recogen siempre las mismas)\n",
        "def selecRandomData(coef, seed):\n",
        "  global df\n",
        "  print(type(coef))\n",
        "  print(df.shape)\n",
        "  hola = df.sample(frac=coef, random_state=seed).copy()\n",
        "  df = hola\n",
        "  print(df.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYx-NVCgmNZ0"
      },
      "source": [
        "#Separación entre conjuntos de datos de entrenamiento y test\n",
        "#coef: introducir el porcentaje de datos deseados para test\n",
        "def separationTestData(coef):\n",
        "  global train\n",
        "  global test \n",
        "  global df\n",
        "  #Separate data for training and test\n",
        "  test_size = int(len(df) * coef) # the test data will be coef% of the entire data\n",
        "  train = df.iloc[:-test_size,:].copy() \n",
        "  test = df.iloc[-test_size:,:].copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtSKSt-ruQAA"
      },
      "source": [
        "#Prepara los datos para la entrada a la red\n",
        "def preparacionInputGRU():\n",
        "  global train\n",
        "  global test\n",
        "  global x_label\n",
        "  global y_label\n",
        "  global x_test\n",
        "  global y_test\n",
        "  global tempmax\n",
        "  #Seleccion de atributos para datos de entrenamiento\n",
        "  x_label = train[[\"humidity\", \"temperature\", \"Inlet\", \"Outlet\", \"Return\", \"x\", \"y\", \"z\", \"time\"]].copy()\n",
        "  y_label = train[\"temperature10min\"].copy()\n",
        "  #Seleccion de atributos para datos de test\n",
        "  x_test = test[[\"humidity\", \"temperature\", \"Inlet\", \"Outlet\", \"Return\", \"x\", \"y\", \"z\", \"time\"]].copy()\n",
        "  y_test = test[\"temperature10min\"].copy()\n",
        "\n",
        "  tempmax = x_label['temperature'].max()\n",
        "\n",
        "  # Normalizacion numerica entre 0 y 1 de los valores numericos, dividiendolos entre el valor maximo de cada atributo\n",
        "  y_label = y_label / y_label.max() \n",
        "  x_label['humidity'] = x_label['humidity'] / x_label['humidity'].max() \n",
        "  x_label['temperature'] = x_label['temperature'] / x_label['temperature'].max() \n",
        "  x_label['x'] = x_label['x'] / x_label['x'].max()\n",
        "  x_label['y'] = x_label['y'] / x_label['y'].max() \n",
        "  x_label['z'] = x_label['z'] / x_label['z'].max()\n",
        "\n",
        "\n",
        "  y_test = y_test / y_test.max() \n",
        "  x_test['humidity'] = x_test['humidity'] / x_test['humidity'].max() \n",
        "  x_test['temperature'] = x_test['temperature'] / x_test['temperature'].max()  \n",
        "  x_test['x'] = x_test['x'] / x_test['x'].max()\n",
        "  x_test['y'] = x_test['y'] / x_test['y'].max() \n",
        "  x_test['z'] = x_test['z'] / x_test['z'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuYTN9WAOtsj"
      },
      "source": [
        "# RED NEURONAL PARA LA TEMPERATURA DE INLET\n",
        "# x_testp: instancias de test a introducir\n",
        "# y_testp: valor real correspondiente a las instancias test introducidas\n",
        "def entrenamientoInlet(x_testp, y_testp):\n",
        "  global x_label\n",
        "  global y_label\n",
        "  global x_test\n",
        "  global y_test\n",
        "  global model\n",
        "  global times\n",
        "  global xin_test\n",
        "  global yin_test\n",
        "\n",
        "  #Se seleccionan unicamente las instancias Inlet para los conjuntos de entrenamiento y test\n",
        "  xin_label = x_label.loc[x_label.Inlet == 1.0].copy()\n",
        "  yin_label = y_label.loc[x_label.Inlet == 1.0].copy()\n",
        "\n",
        "  del(xin_label['Inlet'])\n",
        "  del(xin_label['Outlet'])\n",
        "  del(xin_label['Return'])\n",
        "  del(xin_label['time'])\n",
        "\n",
        "\n",
        "  xin_trainn = np.array(xin_label)\n",
        "  yin_train = np.array(yin_label)\n",
        "\n",
        "  xin_testm = x_test.loc[x_test.Inlet == 1.0].copy()\n",
        "  yin_testm = y_test.loc[x_test.Inlet == 1.0].copy()\n",
        "\n",
        "  del(xin_testm['Inlet'])\n",
        "  del(xin_testm['Outlet'])\n",
        "  del(xin_testm['Return'])\n",
        "  times = xin_testm['time']\n",
        "  del(xin_testm['time'])\n",
        "\n",
        "  xin_testt = np.array(xin_testm)\n",
        "  yin_test = np.array(yin_testm)\n",
        "\n",
        "  xin_train = np.expand_dims(xin_trainn, axis=-1)\n",
        "  xin_test = np.expand_dims(xin_testt, axis=-1)\n",
        "\n",
        "\n",
        "  n_input = 16 #how many samples/rows/timesteps to look in the past in order to forecast the next sample\n",
        "  nin_features= xin_train.shape[1] # how many predictors/Xs/features we have to predict y\n",
        "  b_size = 32 # Number of timeseries samples in each batch\n",
        "  \n",
        "  #Construccion de la red neuronal\n",
        "  #model.add(tf.keras.layers.GRU(256, return_sequences=True, input_shape=[5,1], bias_initializer='zeros'))\n",
        "  tf.keras.layers.InputLayer(\n",
        "    input_shape=(5,))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=5, kernel_size=4, strides=1, padding=\"same\", input_shape=[None, 1]))\n",
        "  model.add(tf.keras.layers.GRU(32, return_sequences=True))\n",
        "  model.add(tf.keras.layers.GRU(32, return_sequences=True))\n",
        "  model.add(tf.keras.layers.GRU(16, return_sequences=True))\n",
        "  model.add(tf.keras.layers.Dense(1)) #Dense layer: it would run slightly faster, the accuracy would be roughly the same, and it would allow us to choose any output activation function we want.\n",
        "\n",
        "  # Establecimiento de parametros de loss, optimizacion y metrics\n",
        "  model.compile(\n",
        "      loss = tf.keras.losses.mean_squared_error,\n",
        "      optimizer='adam',\n",
        "      metrics=['mean_squared_error']\n",
        "  )\n",
        "\n",
        "  #Entrenamiento del modelo\n",
        "  model.fit(xin_train, yin_train, batch_size = 32, epochs = 5)\n",
        "  #Evaluacion de la calidad del modelo\n",
        "  print(\"Evaluate on test data\")\n",
        "  results = model.evaluate(x_testp, y_testp, batch_size=128)\n",
        "  print(\"test loss, test acc:\", results)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcTft6olU7Qb"
      },
      "source": [
        "# RED NEURONAL PARA LA TEMPERATURA DE OUTLET\n",
        "# x_testp: instancias de test a introducir\n",
        "# y_testp: valor real correspondiente a las instancias test introducidas\n",
        "\n",
        "def entrenamientoOutlet(x_testp, y_testp ):\n",
        "  global x_label\n",
        "  global y_label\n",
        "  global x_test\n",
        "  global y_test\n",
        "  global model\n",
        "  global times\n",
        "  global xout_test\n",
        "  global yout_test\n",
        "\n",
        "  \n",
        "  xout_label = x_label.loc[x_label.Outlet == 1.0].copy()\n",
        "  yout_label = y_label.loc[x_label.Outlet == 1.0].copy()\n",
        "\n",
        "  del(xout_label['Inlet'])\n",
        "  del(xout_label['Outlet'])\n",
        "  del(xout_label['Return'])\n",
        "  del(xout_label['time'])\n",
        "\n",
        "\n",
        "  xout_trainn = np.array(xout_label)\n",
        "  yout_train = np.array(yout_label)\n",
        "\n",
        "  xout_testm = x_test.loc[x_test.Outlet == 1.0].copy()\n",
        "  yout_testm = y_test.loc[x_test.Outlet == 1.0].copy()\n",
        "\n",
        "  del(xout_testm['Inlet'])\n",
        "  del(xout_testm['Outlet'])\n",
        "  del(xout_testm['Return'])\n",
        "  times = xout_testm['time']\n",
        "  del(xout_testm['time'])\n",
        "\n",
        "  xout_testt = np.array(xout_testm)\n",
        "  yout_test = np.array(yout_testm)\n",
        "\n",
        "  xout_train = np.expand_dims(xout_trainn, axis=-1)\n",
        "  xout_test = np.expand_dims(xout_testt, axis=-1)\n",
        "\n",
        "  n_input = 16 #how many samples/rows/timesteps to look in the past in order to forecast the next sample\n",
        "  nin_features= xout_train.shape[1] # how many predictors/Xs/features we have to predict y\n",
        "  b_size = 32 # Number of timeseries samples in each batch\n",
        "  \n",
        "  #Construccion red neuronal\n",
        "  tf.keras.layers.InputLayer(\n",
        "    input_shape=(5,))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=5, kernel_size=4, strides=1, padding=\"same\", input_shape=[None, 1]))\n",
        "  model.add(tf.keras.layers.GRU(256, return_sequences=True))\n",
        "  model.add(tf.keras.layers.GRU(256, return_sequences=True))\n",
        "  model.add(tf.keras.layers.GRU(128, return_sequences=True))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\")) #Dense layer: it would run slightly faster, the accuracy would be roughly the same, and it would allow us to choose any output activation function we want.\n",
        "\n",
        "  # Establecimiento de parametros de loss, optimizacion y metrics\n",
        "  model.compile(\n",
        "      loss = tf.keras.losses.mean_squared_error,\n",
        "      optimizer='adam',\n",
        "      metrics=['mean_squared_error']\n",
        "  )\n",
        "\n",
        "  # Entrenamiento del modelo\n",
        "  model.fit(xout_train, yout_train, batch_size = 32, epochs = 5)\n",
        "\n",
        "  #Evaluacion de la calidad del modelo\n",
        "  print(\"Evaluate on test data\")\n",
        "  results = model.evaluate(x_testp, y_testp, batch_size=128)\n",
        "  print(\"test loss, test acc:\", results)\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEZ7dEMC1DKb"
      },
      "source": [
        "# RED NEURONAL PARA LA TEMPERATURA DE RETURN\n",
        "\n",
        "def entrenamientoReturn():\n",
        "  global x_label\n",
        "  global y_label\n",
        "  global x_test\n",
        "  global y_test\n",
        "  global model\n",
        "  global times\n",
        "  global xret_test\n",
        "  global yret_test\n",
        "\n",
        "  xret_label = x_label.loc[x_label.Return == 1.0].copy()\n",
        "  yret_label = y_label.loc[x_label.Return == 1.0].copy()\n",
        "\n",
        "  del(xret_label['Inlet'])\n",
        "  del(xret_label['Outlet'])\n",
        "  del(xret_label['Return'])\n",
        "  del(xret_label['time'])\n",
        "\n",
        "\n",
        "  xret_trainn = np.array(xret_label)\n",
        "  yret_train = np.array(yret_label)\n",
        "\n",
        "  xret_testm = x_test.loc[x_test.Return == 1.0].copy()\n",
        "  yret_testm = y_test.loc[x_test.Return == 1.0].copy()\n",
        "\n",
        "  del(xret_testm['Inlet'])\n",
        "  del(xret_testm['Outlet'])\n",
        "  del(xret_testm['Return'])\n",
        "  times = xret_testm['time']\n",
        "  del(xret_testm['time'])\n",
        "\n",
        "  xret_testt = np.array(xret_testm)\n",
        "  yret_test = np.array(yret_testm)\n",
        "\n",
        "  xret_train = np.expand_dims(xret_trainn, axis=-1)\n",
        "  xret_test = np.expand_dims(xret_testt, axis=-1)\n",
        "\n",
        "  n_input = 16 #how many samples/rows/timesteps to look in the past in order to forecast the next sample\n",
        "  nin_features= xret_train.shape[1] # how many predictors/Xs/features we have to predict y\n",
        "  b_size = 32 # Number of timeseries samples in each batch\n",
        "  \n",
        "  #Construccion red neuronal\n",
        "  model = tf.keras.Sequential()\n",
        "  tf.keras.layers.InputLayer(\n",
        "    input_shape=(5,))\n",
        "  model.add(tf.keras.layers.Conv1D(filters=5, kernel_size=4, strides=1, padding=\"same\", input_shape=[None, 1]))\n",
        "  model.add(tf.keras.layers.GRU(256, return_sequences=True))\n",
        "  model.add(tf.keras.layers.GRU(256, return_sequences=True))\n",
        "  model.add(tf.keras.layers.GRU(128, return_sequences=True))\n",
        "  model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  # Establecimiento de parametros de loss, optimizacion y metrics\n",
        "  model.compile(\n",
        "      loss = tf.keras.losses.mean_squared_error,\n",
        "      optimizer='adam',\n",
        "      metrics=['mean_squared_error']\n",
        "  )\n",
        "\n",
        "  #Entrenamiento del modelo\n",
        "  model.fit(xret_train, yret_train, batch_size = 32, epochs = 5)\n",
        "\n",
        "  #Evaluacion de la calidad del modelo\n",
        "  print(\"Evaluate on test data\")\n",
        "  results = model.evaluate(xret_test, yret_test, batch_size=128)\n",
        "  print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21vnIMECuRm3"
      },
      "source": [
        "#Prediccion para comprobar resultados del modelo con nuevos datos de entrada\n",
        "#coefmuestras: el coeficiente \n",
        "def predecir(coefmuestras, x_testo, y_testo, tipo):\n",
        "  global model\n",
        "  global xin_test\n",
        "  global times\n",
        "  global yin_test\n",
        "  global xout_test\n",
        "  global yout_test\n",
        "  global xret_test\n",
        "  global yret_test\n",
        "  global tempmax\n",
        "  global predictions\n",
        "\n",
        "  predictions = model.predict(x_testo, verbose = 2)\n",
        "  predictionsreal = predictions*tempmax\n",
        "  preds = np.squeeze(np.asarray(predictionsreal))\n",
        "  inlet10min = y_testo*tempmax\n",
        "  timesdesnorm = (24*60)*times\n",
        "  \n",
        "  plt.plot(timesdesnorm[0:1000], preds[0: 1000, 4], 'bo', label = \"Temperatura predicha\")\n",
        "  plt.plot(timesdesnorm[0:1000], inlet10min[0:1000], 'ro',  label = \"Temperatura real\")\n",
        "\n",
        "  plt.xlabel('Tiempo (min)')\n",
        "  plt.ylabel('Temperatura de Inlet (ºC)')\n",
        "\n",
        "  plt.title(\"Temperatura de \"+ str(tipo), \n",
        "                fontdict={'family': 'serif', \n",
        "                          'color' : 'darkblue',\n",
        "                          'weight': 'bold',\n",
        "                          'size': 18})\n",
        "\n",
        "\n",
        "  \n",
        "                      \n",
        "                      \n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiCHD9s6HDkQ"
      },
      "source": [
        "# Entrenamiento y test distribucion uniforme de los sensores a lo largo de la sala\n",
        "# tipo: tipo de temperatura requerida para el entrenamiento (inlet, outlet)\n",
        "def selecRacks(tipo):\n",
        "  global df \n",
        "  global predictions\n",
        "  global model\n",
        "  global x_test \n",
        "  global Y_test\n",
        "  global xin_test\n",
        "  global xout_test\n",
        "  global yout_test\n",
        "  global times\n",
        "  global yin_test\n",
        "  global tempmax\n",
        "  mses = []\n",
        "  coefs = [0.3, 0.4]\n",
        "  #Se prepara el conjunto de training y test con los datos globales\n",
        "  if tipo == \"inlet\":\n",
        "    preparacionDataFrame()\n",
        "    separationTestData(0.33)\n",
        "    preparacionInputGRU()\n",
        "    xin_testm = x_test.loc[x_test.Inlet == 1.0].copy()\n",
        "    yin_testm = y_test.loc[x_test.Inlet == 1.0].copy()\n",
        "    del(xin_testm['Inlet'])\n",
        "    del(xin_testm['Outlet'])\n",
        "    del(xin_testm['Return'])\n",
        "    times = xin_testm['time']\n",
        "    del(xin_testm['time'])\n",
        "    xin_testt = np.array(xin_testm)\n",
        "    yin_testpp = np.array(yin_testm)\n",
        "    xin_testpp = np.expand_dims(xin_testt, axis=-1)\n",
        "\n",
        "  elif tipo == \"outlet\":\n",
        "    preparacionDataFrame()\n",
        "    separationTestData(0.33)\n",
        "    preparacionInputGRU()\n",
        "    xout_testm = x_test.loc[x_test.Outlet == 1.0].copy()\n",
        "    yout_testm = y_test.loc[x_test.Outlet == 1.0].copy()\n",
        "    del(xout_testm['Inlet'])\n",
        "    del(xout_testm['Outlet'])\n",
        "    del(xout_testm['Return'])\n",
        "    times = xout_testm['time']\n",
        "    del(xout_testm['time'])\n",
        "    xout_testt = np.array(xout_testm)\n",
        "    yout_testpp = np.array(yout_testm)\n",
        "    xout_testpp = np.expand_dims(xout_testt, axis=-1)\n",
        "\n",
        "  #Se prepara el conjunto usado para el entrenamiento\n",
        "  preparacionDataFrame()\n",
        "  df = df[(df['rack']=='MAD1.410.R2B06') | (df['rack'] == 'MAD1.410.R2B08')| (df['rack'] == 'MAD1.410.R2B10') | (df['rack'] == 'MAD1.410.R2B12') | (df['rack'] == 'MAD1.410.R1B05') | (df['rack'] == 'MAD1.410.R1B08') | (df['rack'] == 'MAD1.410.R1B11') | (df['rack'] == 'MAD1.410.R1B13')]\n",
        "  separationTestData(0.33)\n",
        "  preparacionInputGRU()\n",
        "  if (tipo == \"inlet\"):\n",
        "    entrenamientoInlet(xin_testpp, yin_testpp)\n",
        "    predecir(1, xin_testpp, yin_testpp, \"Inlet\")\n",
        "    inlet10min = np.squeeze(np.asarray(yin_testpp))\n",
        "\n",
        "  elif (tipo == \"outlet\"):\n",
        "    entrenamientoOutlet(xout_testpp, yout_testpp)\n",
        "    predecir(1, xout_test, yout_test, \"Outlet\")\n",
        "    inlet10min = np.squeeze(np.asarray(yout_test))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "selecRacks(\"outlet\")\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oPBdJ-B_Th2"
      },
      "source": [
        "#Entrenamiento y test respectivos al experimento global\n",
        "#tipo: el tipo de temperatura requerida\n",
        "def GRUGlobali(tipo):\n",
        "\n",
        "  global xin_test\n",
        "  global xout_test\n",
        "  global yin_test\n",
        "  global yout_test\n",
        "  global yret_test\n",
        "  global xret_test\n",
        "  global predictions\n",
        "  global model\n",
        "  if tipo == \"inlet\":\n",
        "    preparacionDataFrame()\n",
        "    separationTestData(0.33)\n",
        "    preparacionInputGRU()\n",
        "    entrenamientoInlet(xin_test, yin_test)\n",
        "    predecir(1, xin_test, yin_test, \"Inlet\")\n",
        "  \n",
        "  elif tipo == \"outlet\":\n",
        "    preparacionDataFrame()\n",
        "    separationTestData(0.33)\n",
        "    preparacionInputGRU()\n",
        "    entrenamientoOutlet(xout_test, yout_test)\n",
        "    predecir(1, xout_test, yout_test, \"Outlet\")\n",
        "\n",
        "  elif tipo == \"return\":\n",
        "    preparacionDataFrame()\n",
        "    separationTestData(0.33)\n",
        "    preparacionInputGRU()\n",
        "    entrenamientoReturn()\n",
        "    predecir(1, xret_test, yret_test, \"Return\")\n",
        "\n",
        "GRUGlobali(\"outlet\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F-bFrv-eloK"
      },
      "source": [
        "#Funcion para estudiar el porcentaje optimo de datos de test\n",
        "#tipo: el tipo de temperatura (\"inlet\", \"outlet\", \"return\")\n",
        "def GRUGlobal(tipo):\n",
        "  global xin_test\n",
        "  global xout_test\n",
        "  global yin_test\n",
        "  global yout_test\n",
        "  global x_test\n",
        "  global y_test\n",
        "  global predictions\n",
        "  global model\n",
        "  mses = []\n",
        "  coefs = [0.1, 0.25, 0.33, 0.4]\n",
        "  \n",
        "  for i in coefs:\n",
        "    print(\"Usamos para test el \" + str(i*100)+ \"% de los datos\")\n",
        "    preparacionDataFrame()\n",
        "    separationTestData(i)\n",
        "    preparacionInputGRU()\n",
        "    if tipo == \"inlet\":\n",
        "      entrenamientoInlet(xin_test, yin_test)\n",
        "      #yin_test = model.predict(xin_test)\n",
        "      predecir(1, xin_test, yin_test, \"Inlet\")\n",
        "      inlet10min = np.squeeze(np.asarray(yin_test))\n",
        "    elif tipo == \"outlet\":\n",
        "      entrenamientoOutlet(xout_test, yout_test)\n",
        "      predecir(1, xout_test, yout_test, \"Outlet\")\n",
        "      inlet10min = np.squeeze(np.asarray(yout_test))\n",
        "    #elif tipo == \"return\":\n",
        "    # print(\"aaa\")\n",
        "    else: \n",
        "      print(\"Tipo no válido\")\n",
        "    \n",
        "    preds = np.squeeze(np.asarray(predictions))\n",
        "    msei = metrics.mean_squared_error(inlet10min, preds[:, 4])\n",
        "    mses.append(msei)\n",
        "\n",
        "  plt.plot(coefs, mses, 'r-',  label = \"Temperatura real\")\n",
        "\n",
        "  plt.xlabel('coeficientes')\n",
        "  plt.ylabel('MSE')\n",
        "\n",
        "  plt.title(\"MSEs\", fontdict={'family': 'serif','color' : 'darkblue','weight': 'bold', 'size': 18})\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "GRUGlobal(\"inlet\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNGPu9IKBF42"
      },
      "source": [
        "#Funcion para el estudio de reducir mediciones en el centro de datos\n",
        "#tipo: el tipo de temperatura (\"inlet\" u \"outlet\")\n",
        "def GRURandomData(tipo):\n",
        "  global xin_test\n",
        "  global xout_test\n",
        "  global yin_test\n",
        "  global yout_test\n",
        "  global predictions\n",
        "  global model\n",
        "  global df\n",
        "  #Los porcentajes de datos a testear\n",
        "  coefs = [0.9, 0.75, 0.66, 0.5]\n",
        "\n",
        "  if tipo == \"inlet\":\n",
        "    preparacionDataFrame()\n",
        "    separationTestData(0.33)\n",
        "    preparacionInputGRU()\n",
        "    xin_testm = x_test.loc[x_test.Inlet == 1.0].copy()\n",
        "    yin_testm = y_test.loc[x_test.Inlet == 1.0].copy()\n",
        "    del(xin_testm['Inlet'])\n",
        "    del(xin_testm['Outlet'])\n",
        "    del(xin_testm['Return'])\n",
        "    times = xin_testm['time']\n",
        "    del(xin_testm['time'])\n",
        "    xin_testt = np.array(xin_testm)\n",
        "    yin_testpp = np.array(yin_testm)\n",
        "    xin_testpp = np.expand_dims(xin_testt, axis=-1)\n",
        "  \n",
        "\n",
        "  elif tipo == \"outlet\":\n",
        "    preparacionDataFrame()\n",
        "    separationTestData(0.33)\n",
        "    preparacionInputGRU()\n",
        "    xout_testm = x_test.loc[x_test.Outlet == 1.0].copy()\n",
        "    yout_testm = y_test.loc[x_test.Outlet == 1.0].copy()\n",
        "    del(xout_testm['Inlet'])\n",
        "    del(xout_testm['Outlet'])\n",
        "    del(xout_testm['Return'])\n",
        "    times = xout_testm['time']\n",
        "    del(xout_testm['time'])\n",
        "    xout_testt = np.array(xout_testm)\n",
        "    yout_testpp = np.array(yout_testm)\n",
        "    xout_testpp = np.expand_dims(xout_testt, axis=-1)\n",
        "\n",
        "  for i in coefs:\n",
        "    print(\"Entrenamiento con el \"+str(i*100)+\"% de los datos\")\n",
        "    preparacionDataFrame()\n",
        "    selecRandomData(i, 1)\n",
        "    separationTestData(0.33)\n",
        "    preparacionInputGRU()\n",
        "    if tipo == \"inlet\":\n",
        "      entrenamientoInlet(xin_testpp, yin_testpp)\n",
        "      predecir(1, xin_testpp, yin_testpp, \"Inlet\")\n",
        "    elif tipo == \"outlet\":\n",
        "      entrenamientoOutlet(xout_testpp, yout_testpp)\n",
        "      predecir(1, xout_testpp, yout_testpp, \"Outlet\")\n",
        "\n",
        "GRURandomData(\"outlet\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}